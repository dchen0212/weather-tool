import streamlit as st
import pandas as pd
from datetime import datetime
from weather_core import get_weather_data  # ä½ åŸæ¥çš„å‡½æ•°ä¿ç•™åœ¨ wt_data.py
import io
import tempfile
import os

# è‡ªåŠ¨æ£€æµ‹ç¼–ç è¯»å– CSV æ–‡ä»¶
def read_csv_with_encoding_detection(uploaded_file):
    import chardet
    pos = uploaded_file.tell()
    sample = uploaded_file.read(1024)
    result = chardet.detect(sample)
    encoding = result['encoding']
    uploaded_file.seek(pos)
    df = pd.read_csv(uploaded_file, encoding=encoding)
    uploaded_file.seek(0)
    return df

st.set_page_config(page_title="å¤©æ°”æ•°æ®æŸ¥è¯¢", layout="centered")

st.title("ğŸŒ¤ï¸ å¤©æ°”æ•°æ®æŸ¥è¯¢ç³»ç»Ÿ")

# è¾“å…¥ç»çº¬åº¦å’Œæ—¥æœŸèŒƒå›´
lat = st.number_input("çº¬åº¦ (Latitude)", value=32.0, format="%.6f")
lon = st.number_input("ç»åº¦ (Longitude)", value=-84.0, format="%.6f")
start_date = st.date_input("èµ·å§‹æ—¥æœŸ", value=datetime(2015, 1, 1))
end_date = st.date_input("ç»“æŸæ—¥æœŸ", value=datetime(2015, 12, 31))

unit = st.radio("æ¸©åº¦å•ä½", ["æ‘„æ°åº¦ (Â°C)", "å¼€å°”æ–‡ (K)"])
unit_code = "C" if "æ‘„æ°" in unit else "K"

# æŒ‰é’®è§¦å‘
if st.button("è·å–å¤©æ°”æ•°æ®"):
    if start_date > end_date:
        st.error("âŒ èµ·å§‹æ—¥æœŸä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ")
    else:
        with st.spinner("æ­£åœ¨è·å–æ•°æ®ï¼Œè¯·ç¨å€™..."):
            try:
                df = get_weather_data(lat, lon, str(start_date), str(end_date), unit=unit_code)
                if df is not None and not df.empty:
                    st.success("âœ… è·å–æˆåŠŸï¼")
                    st.dataframe(df)

                    # ä¸‹è½½é“¾æ¥
                    filename = f"weather_{start_date}_{end_date}_{lat}_{lon}.csv"
                    csv = df.to_csv(index=False).encode("utf-8")
                    st.download_button("ğŸ“¥ ä¸‹è½½ CSV æ–‡ä»¶", csv, file_name=filename, mime="text/csv")
                else:
                    st.warning("âš ï¸ æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆæ•°æ®ã€‚")
            except Exception as e:
                st.error(f"âŒ å‡ºé”™ï¼š{e}")

# --- é¢„æµ‹ NC æ–‡ä»¶è¯»å–ä¸ CSV å¯¼å‡ºæ¨¡å— ---
st.markdown("---")
st.header("ğŸ“‚ é¢„æµ‹ NC æ•°æ®è½¬æ¢ä¸º CSV")

import netCDF4 as nc
import numpy as np
import h5py

# å¤©æ°”å‚æ•°åˆ†ç±»å…³é”®è¯
weather_categories = {
    'temperature': {'keywords': ['temp', 't2m', 'temperature', 'air_temp', 'ta']},
    'wind': {'keywords': ['wind', 'u', 'v', 'wind_speed', 'ua', 'va']},
    'humidity': {'keywords': ['humidity', 'rh', 'q', 'hus']},
    'pressure': {'keywords': ['pressure', 'sp', 'slp']},
    'precipitation': {'keywords': ['precip', 'rain', 'snow', 'prcp']},
    'radiation': {'keywords': ['rad', 'solar', 'swdown']},
    'geopotential': {'keywords': ['zg', 'geopotential', 'height']}
}

def identify_weather_vars(nc_file):
    """è¯†åˆ«æ–‡ä»¶ä¸­çš„å¤©æ°”å˜é‡å¹¶åˆ†ç±»"""
    identified = {}
    for var_name in nc_file.variables:
        if var_name.lower() in ['time', 'latitude', 'longitude', 'lat', 'lon', 'level', 'pressure']:
            continue
        var_name_lower = var_name.lower()
        for category, props in weather_categories.items():
            if any(kw in var_name_lower for kw in props['keywords']):
                identified[var_name] = category
                break
    return identified

def extract_location_data(var, lat_idx, lon_idx):
    """æå–ç‰¹å®šä½ç½®çš„æ•°æ®å¹¶å±•å¹³"""
    try:
        dims = var.dimensions
        if len(dims) == 4:
            data = var[:, 0, lat_idx, lon_idx]
        elif len(dims) == 3:
            data = var[:, lat_idx, lon_idx]
        elif len(dims) == 2:
            data = var[:, lat_idx]
        else:
            data = var[:]
        if hasattr(data, "ndim"):
            if data.ndim == 0:
                data = [data.item()]
            elif data.ndim == 1:
                data = data
            else:
                data = data.flatten()
        return data
    except Exception:
        return None

def process_nc_streamlit(uploaded_file):
    """å¤„ç†ä¸Šä¼ çš„NCæ–‡ä»¶"""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".nc") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_file.flush()
            try:
                ds = nc.Dataset(tmp_file.name, 'r')
                result = process_valid_nc(ds)
                ds.close()
                os.unlink(tmp_file.name)
                if result is None:
                    return pd.DataFrame()
                return result
            except OSError as e:
                if 'NetCDF: HDF error' in str(e):
                    try:
                        with h5py.File(tmp_file.name, 'r') as h5_file:
                            os.unlink(tmp_file.name)
                            st.error("âš ï¸ æš‚ä¸æ”¯æŒå¤æ‚HDF5è§£æï¼Œè¿™é‡Œå¯æ‰©å±•")
                            return pd.DataFrame()
                    except Exception as e2:
                        os.unlink(tmp_file.name)
                        st.error(f"âŒ HDF5å¤„ç†å¤±è´¥: {e2}")
                        return pd.DataFrame()
                else:
                    os.unlink(tmp_file.name)
                    st.error(f"âŒ å¤„ç†å¤±è´¥: {e}")
                    return pd.DataFrame()
    except Exception as e:
        st.error(f"âŒ å¤„ç†å¤±è´¥: {e}")
        return pd.DataFrame()

def process_valid_nc(nc_file):
    """æ­£å¸¸netCDF4å¤„ç†"""
    lat_var = nc_file.variables.get('latitude') or nc_file.variables.get('lat')
    lon_var = nc_file.variables.get('longitude') or nc_file.variables.get('lon')
    if lat_var is None or lon_var is None:
        st.error("âŒ ç¼ºå°‘ç»çº¬åº¦å˜é‡")
        return None
    lats = lat_var[:]
    lons = lon_var[:]
    lat_idx = np.abs(lats - lats.mean()).argmin()
    lon_idx = np.abs(lons - lons.mean()).argmin()
    actual_lat, actual_lon = lats[lat_idx], lons[lon_idx]

    time_var = nc_file.variables.get('time')
    if time_var is not None:
        try:
            times = nc.num2date(time_var[:], time_var.units)
            time_strs = [t.strftime('%Y-%m-%d %H:%M:%S') for t in times]
        except Exception:
            time_strs = [f"time_{i}" for i in range(len(time_var))]
    else:
        time_strs = [f"time_{i}" for i in range(10)]

    data = {
        "date": time_strs,
        "lat": [actual_lat] * len(time_strs),
        "lon": [actual_lon] * len(time_strs)
    }

    weather_vars = identify_weather_vars(nc_file)
    for var_name, category in weather_vars.items():
        var = nc_file.variables[var_name]
        var_data = extract_location_data(var, lat_idx, lon_idx)
        if var_data is not None and len(var_data) == len(time_strs):
            data[f"{category}_{var_name}"] = var_data

    return pd.DataFrame(data)

# æ–‡ä»¶ä¸Šä¼ 
nc_file = st.file_uploader("ä¸Šä¼ é¢„æµ‹ NC æ–‡ä»¶ï¼ˆ.ncï¼‰", type=["nc"], key="pred_nc")
if nc_file is not None:
    df_nc = process_nc_streamlit(nc_file)
    if df_nc is not None and not df_nc.empty:
        st.write(f"**çº¬åº¦ (Latitude)**: {df_nc['lat'].iloc[0]}")
        st.write(f"**ç»åº¦ (Longitude)**: {df_nc['lon'].iloc[0]}")
        st.subheader("ğŸ“Œ é¢„æµ‹ NC æ•°æ®é¢„è§ˆ")
        st.dataframe(df_nc.head(10))
        csv_data = df_nc.to_csv(index=False).encode("utf-8")
        st.download_button(
            "ğŸ“¥ ä¸‹è½½é¢„æµ‹æ•°æ® CSV",
            csv_data,
            file_name="predicted_nc_data.csv",
            mime="text/csv"
        )

# --- çœŸå® vs é¢„æµ‹ CSV æ•°æ®å¯¹æ¯”æ¨¡å— ---
real_file = st.file_uploader("ä¸Šä¼ çœŸå®å¤©æ°” CSV æ–‡ä»¶", type=["csv"], key="real_file")
pred_file = st.file_uploader("ä¸Šä¼ é¢„æµ‹å¤©æ°” CSV æ–‡ä»¶", type=["csv"], key="pred_file")

# åªæœ‰åœ¨ real_file å’Œ pred_file éƒ½å·²ä¸Šä¼ æ—¶æ‰è¿›è¡Œåˆ†æ
if real_file and pred_file:
    st.header("ğŸ“Š çœŸå® vs é¢„æµ‹æ•°æ®å¯¹æ¯”åˆ†æ")
    try:
        # è‡ªåŠ¨æ£€æµ‹ç¼–ç è¯»å–
        df_real = read_csv_with_encoding_detection(real_file)
        df_pred = read_csv_with_encoding_detection(pred_file)

        # è‡ªåŠ¨æ£€æµ‹å¯å¯¹æ¯”çš„å…¬å…±å­—æ®µï¼ˆåŒ…æ‹¬æ¸©åº¦ã€é™æ°´ã€å…‰ç…§ç­‰ï¼‰
        compare_fields = [col for col in df_real.columns if col in df_pred.columns]
        # ç§»é™¤æ— æ„ä¹‰å­—æ®µå¦‚æ—¥æœŸå­—æ®µ
        compare_fields = [col for col in compare_fields if col.lower() != 'date']

        if not compare_fields:
            st.error("âŒ æœªæ‰¾åˆ°ä¸¤ä¸ªæ–‡ä»¶ä¸­å…±æœ‰çš„å¯¹æ¯”å­—æ®µ")
        else:
            target_col = st.selectbox("è¯·é€‰æ‹©å¯¹æ¯”å­—æ®µï¼š", compare_fields)
            if target_col.lower() == "date":
                st.warning("âš ï¸ å­—æ®µ 'date' ä¸ºæ—¶é—´å­—æ®µï¼Œä¸è¿›è¡Œè¯¯å·®è®¡ç®—ä¸ç»˜å›¾ã€‚")
            else:
                y_true = df_real[target_col].reset_index(drop=True)
                y_pred = df_pred[target_col].reset_index(drop=True)

                # æ•°æ®é¢„è§ˆï¼ˆå‰10è¡Œï¼‰
                st.subheader("ğŸ“Œ æ•°æ®é¢„è§ˆ (å‰10è¡Œ)")
                st.dataframe(pd.DataFrame({
                    "çœŸå®å€¼": y_true.head(10),
                    "é¢„æµ‹å€¼": y_pred.head(10)
                }))

                from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
                import numpy as np
                import matplotlib.pyplot as plt

                mae = mean_absolute_error(y_true, y_pred)
                rmse = np.sqrt(mean_squared_error(y_true, y_pred))
                r2 = r2_score(y_true, y_pred)

                # æ¯7å¤©è®¡ç®— MAE å¹¶ç»˜å›¾
                weekly_mae = [mean_absolute_error(y_true[i:i+7], y_pred[i:i+7]) for i in range(0, len(y_true), 7)]
                weekly_rmse = [np.sqrt(mean_squared_error(y_true[i:i+7], y_pred[i:i+7])) for i in range(0, len(y_true), 7)]
                weekly_r2 = [r2_score(y_true[i:i+7], y_pred[i:i+7]) for i in range(0, len(y_true), 7)]

                # æ–°å¢æ¯ä¸¤å‘¨å’Œæ¯æœˆè¯¯å·®è®¡ç®—
                biweekly_mae = [mean_absolute_error(y_true[i:i+14], y_pred[i:i+14]) for i in range(0, len(y_true), 14)]
                monthly_mae = [mean_absolute_error(y_true[i:i+30], y_pred[i:i+30]) for i in range(0, len(y_true), 30)]

                biweekly_rmse = [np.sqrt(mean_squared_error(y_true[i:i+14], y_pred[i:i+14])) for i in range(0, len(y_true), 14)]
                monthly_rmse = [np.sqrt(mean_squared_error(y_true[i:i+30], y_pred[i:i+30])) for i in range(0, len(y_true), 30)]

                biweekly_r2 = [r2_score(y_true[i:i+14], y_pred[i:i+14]) for i in range(0, len(y_true), 14)]
                monthly_r2 = [r2_score(y_true[i:i+30], y_pred[i:i+30]) for i in range(0, len(y_true), 30)]

                ae = np.abs(y_true - y_pred)
                error = y_pred - y_true

                interval = st.selectbox("é€‰æ‹©æ—¶é—´å°ºåº¦", ["æ¯å‘¨", "æ¯ä¸¤å‘¨", "æ¯æœˆ"], key="interval_select")

                interval_map = {
                    "æ¯å‘¨": "Weekly",
                    "æ¯ä¸¤å‘¨": "Biweekly",
                    "æ¯æœˆ": "Monthly"
                }
                interval_en = interval_map[interval]

                if interval == "æ¯å‘¨":
                    mae_vals = weekly_mae
                    rmse_vals = weekly_rmse
                    r2_vals = weekly_r2
                elif interval == "æ¯ä¸¤å‘¨":
                    mae_vals = biweekly_mae
                    rmse_vals = biweekly_rmse
                    r2_vals = biweekly_r2
                else:
                    mae_vals = monthly_mae
                    rmse_vals = monthly_rmse
                    r2_vals = monthly_r2

                with st.expander("ğŸ“Š æŸ¥çœ‹è¯¦ç»†è¯¯å·®ä¿¡æ¯"):
                    st.subheader(f"{interval} MAE")
                    st.dataframe(pd.DataFrame({"Interval": list(range(1, len(mae_vals)+1)), "MAE": mae_vals}))

                    st.subheader(f"{interval} RMSE")
                    st.dataframe(pd.DataFrame({"Interval": list(range(1, len(rmse_vals)+1)), "RMSE": rmse_vals}))

                    st.subheader(f"{interval} RÂ²")
                    st.dataframe(pd.DataFrame({"Interval": list(range(1, len(r2_vals)+1)), "RÂ²": r2_vals}))

                    st.subheader("å‰10ä¸ªç»å¯¹è¯¯å·® (AE)")
                    st.dataframe(ae.head(10))

                    st.subheader("å‰10ä¸ªè¯¯å·® (Error)")
                    st.dataframe(error.head(10))

                st.write(f"**MAE**: {mae:.3f}")
                st.write(f"**RMSE**: {rmse:.3f}")
                st.write(f"**RÂ²**: {r2:.3f}")

                # æŠ˜çº¿å›¾
                fig, ax = plt.subplots(figsize=(10, 4))
                ax.plot(y_true.index, y_true, label="çœŸå®å€¼")
                ax.plot(y_pred.index, y_pred, label="é¢„æµ‹å€¼", linestyle="--")
                ax.set_title(f"{target_col} Comparison Line Chart")
                ax.set_xlabel("Index")
                ax.set_ylabel(target_col)
                ax.legend(["True Value", "Predicted Value"])
                st.pyplot(fig)

                fig2, ax2 = plt.subplots(figsize=(10, 4))
                ax2.plot(ae, label="Absolute Error (AE)")
                ax2.plot(error, label="Error")
                ax2.set_title(f"{target_col} Error Line Chart")
                ax2.set_xlabel("Index")
                ax2.set_ylabel("Error Value")
                ax2.legend()
                st.pyplot(fig2)

                fig3, ax3 = plt.subplots(figsize=(10, 4))
                ax3.plot(mae_vals, marker='o', label=f"{interval_en} MAE")
                ax3.set_title(f"{interval_en} MAE for {target_col}")
                ax3.set_xlabel("Interval Index")
                ax3.set_ylabel("MAE")
                ax3.legend()
                st.pyplot(fig3)

                fig4, ax4 = plt.subplots(figsize=(10, 4))
                ax4.plot(rmse_vals, marker='o', label=f"{interval_en} RMSE", color='orange')
                ax4.set_title(f"{interval_en} RMSE for {target_col}")
                ax4.set_xlabel("Interval Index")
                ax4.set_ylabel("RMSE")
                ax4.legend()
                st.pyplot(fig4)

                fig5, ax5 = plt.subplots(figsize=(10, 4))
                ax5.plot(r2_vals, marker='o', label=f"{interval_en} RÂ²", color='green')
                ax5.set_title(f"{interval_en} RÂ² for {target_col}")
                ax5.set_xlabel("Interval Index")
                ax5.set_ylabel("RÂ²")
                ax5.legend()
                st.pyplot(fig5)
    except Exception as e:
        st.error(f"âŒ å¯¹æ¯”å‡ºé”™ï¼š{e}")
